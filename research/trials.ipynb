{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"e:\\GITHUB\\Crime-Investigator\\data\")#change directory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd #working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65126160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "  loader = DirectoryLoader(\n",
    "    data,                     #path\n",
    "    glob=\"*.pdf\",             #only the pdfs(all pdfs)\n",
    "    loader_cls=PyPDFLoader    #to load pdf documents langchain help\n",
    "  )\n",
    "  documents = loader.load()\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_files(r\"e:\\GITHUB\\Crime-Investigator\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde59c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to get only wanted (ex remove meta data)\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_doc(docs: List[Document]) -> List[Document]:\n",
    "    \n",
    "    \"\"\"Filter document objs to return a newlist of doc objects to only \n",
    "    include 'source' in metadata and page content.\"\"\"\n",
    "\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src= doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_doc=filter_to_minimal_doc(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73340617",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdcb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split documents into small chunks\n",
    "def text_split(minimal_doc):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=20,      #to understand context with chunks\n",
    "    )\n",
    "  texts_chunk=text_splitter.split_documents(minimal_doc)\n",
    "  return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunk=text_split(minimal_doc)\n",
    "print(f\"Number of chunks {len(text_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "193d5ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_21000\\2399630773.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_21000\\2399630773.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b026fdcbd944332a886b4072180f43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_21000\\2399630773.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b026fdcbd944332a886b4072180f43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Embeddding - using huggingface model\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "        )\n",
    "    return embeddings\n",
    "\n",
    "embedding=download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=embedding.embed_query(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7734cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df36d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\n",
    "GEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "OPENROUTER_API_KEY=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\n",
    "os.environ[\"GEMINI_API_KEY\"]=GEMINI_API_KEY\n",
    "os.environ[\"OPENROUTER_API_KEY\"]=OPENROUTER_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce35bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key=PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "465901a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec \n",
    "\n",
    "index_name=\"crime-investigater\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,                   #dimension of the embedding vector\n",
    "        metric=\"cosine\",                 #similarity measure\n",
    "        spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\") #serverless configuration\n",
    "    )\n",
    "\n",
    "index=pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9464438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to existing Pinecone index: crime-investigater\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Connect to existing Pinecone index (no need to upload documents again)\n",
    "docsearch = PineconeVectorStore(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Connected to existing Pinecone index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "758d006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 3})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs=retriever.invoke(\"First things to do in a murder case?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eff3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2d9c634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! üòä It's lovely to hear from you! How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Configure LLM to use OpenRouter with Gemma model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"google/gemma-3-12b-it:free\",\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "response = llm.invoke(\"Say hello!\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bcc006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (1.2.8)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (1.2.9)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (0.6.8)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (4.14.1)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install missing langchain components\n",
    "%pip install --upgrade langchain langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0675d65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: langchain 1.2.8 does not provide the extra 'all'\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install all required langchain packages\n",
    "%pip install langchain[all] --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "867901fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Alternative approach: Create RAG chain manually\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618544ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prompt template created (Gemma-compatible)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an expert crime investigator assistant with deep knowledge of forensic procedures.\n",
    "    \n",
    "Context from crime investigation documents:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Provide a clear, actionable answer based on the context above. Use three sentences maximum and keep the answer concise.\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2730959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG chain created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create RAG chain manually\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build the RAG chain\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7b361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: What to do first in a murder scene?\n",
      "\n",
      "üîç Answer:\n",
      "In a murder scene, the first priority is to determine the victim's status ‚Äì whether they are alive or deceased. This must be done before touching or moving any objects. Following this assessment, investigators should photograph and/or video the entire crime scene.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG chain with a crime investigation question\n",
    "question = \"What to do first in a murder scene?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "response = rag_chain.invoke(question)\n",
    "print(f\"Answer:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb9943",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19606014",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d2593b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installed packages for requirements.txt:\n",
      "\n",
      "flask==3.1.2\n",
      "langchain==1.2.8\n",
      "langchain-community==0.4.1\n",
      "langchain-core==1.2.9\n",
      "langchain-openai==1.1.7\n",
      "langchain-pinecone==0.2.13\n",
      "pinecone==7.3.0\n",
      "pypdf==6.6.2\n",
      "python-dotenv==1.0.1\n",
      "sentence-transformers==5.2.2\n",
      "\n",
      "‚úÖ requirements.txt updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get list of installed packages to update requirements.txt\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "result = subprocess.run([sys.executable, '-m', 'pip', 'list', '--format=freeze'], \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "# Filter only the relevant packages for this project\n",
    "relevant_packages = [\n",
    "    'langchain', 'langchain-openai', 'langchain-pinecone', 'langchain-community', \n",
    "    'langchain-core', 'sentence-transformers', 'pinecone', 'pypdf', \n",
    "    'python-dotenv', 'flask'\n",
    "]\n",
    "\n",
    "installed = {}\n",
    "for line in result.stdout.split('\\n'):\n",
    "    if '==' in line:\n",
    "        pkg_name, version = line.split('==')\n",
    "        pkg_lower = pkg_name.lower()\n",
    "        for rel_pkg in relevant_packages:\n",
    "            if pkg_lower == rel_pkg.lower() or pkg_lower.replace('-', '_') == rel_pkg.replace('-', '_'):\n",
    "                installed[rel_pkg] = version\n",
    "                break\n",
    "\n",
    "print(\"üì¶ Installed packages for requirements.txt:\\n\")\n",
    "requirements_content = []\n",
    "for pkg, ver in sorted(installed.items()):\n",
    "    line = f\"{pkg}=={ver}\"\n",
    "    print(line)\n",
    "    requirements_content.append(line)\n",
    "\n",
    "# Add the -e . at the end\n",
    "requirements_content.append(\"-e .\")\n",
    "\n",
    "# Save to requirements.txt\n",
    "with open(r\"e:\\GITHUB\\Crime-Investigator\\requirements.txt\", 'w') as f:\n",
    "    f.write('\\n'.join(requirements_content))\n",
    "\n",
    "print(\"\\n‚úÖ requirements.txt updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61257bff",
   "metadata": {},
   "source": [
    "## üìã Updated requirements.txt\n",
    "\n",
    "The [requirements.txt](../requirements.txt) file has been updated with all packages currently installed in the notebook environment:\n",
    "\n",
    "- **flask==3.1.2** - Web framework\n",
    "- **langchain==1.2.8** - LangChain core\n",
    "- **langchain-community==0.4.1** - Community integrations\n",
    "- **langchain-core==1.2.9** - LangChain core utilities\n",
    "- **langchain-openai==1.1.7** - OpenAI/OpenRouter integration\n",
    "- **langchain-pinecone==0.2.13** - Pinecone vector store\n",
    "- **pinecone==7.3.0** - Pinecone client\n",
    "- **pypdf==6.6.2** - PDF processing\n",
    "- **python-dotenv==1.0.1** - Environment variables\n",
    "- **sentence-transformers==5.2.2** - Embedding models\n",
    "- **-e .** - Editable install of Crime Investigator package"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
